{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import shutil\n",
    "import time\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Iterable, Literal, Self\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from jax import random\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from heidelberg_v01 import (\n",
    "    load_data,\n",
    "    load_datasets,\n",
    "    plot_error,\n",
    "    plot_spikes,\n",
    "    plot_traces,\n",
    "    run,\n",
    "    run_example,\n",
    ")\n",
    "from spikegd.theta import ThetaNeuron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from h5 file\n",
      "Loading audio filenames\n",
      "Finished loading SHD\n",
      "Loading data from h5 file\n",
      "Loading audio filenames\n",
      "Finished loading SHD\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(\"data\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_theta(config: dict, data_loaders=None):\n",
    "    \"\"\"\n",
    "    Wrapper to train a network of Theta neurons with the given configuration.\n",
    "\n",
    "    See docstring of `run` and article for more information.\n",
    "    \"\"\"\n",
    "    if data_loaders is None:\n",
    "        data_loaders = load_data(datasets, config)\n",
    "\n",
    "    tau, I0, eps = config[\"tau\"], config[\"I0\"], config[\"eps\"]\n",
    "    neuron = ThetaNeuron(tau, I0, eps)\n",
    "    metrics, perf_metrics = run(neuron, data_loaders, config, progress_bar=\"script\")\n",
    "    return metrics, perf_metrics\n",
    "\n",
    "def run_theta_ensemble(config: dict, samples: int = 1, data_loaders=None) -> dict:\n",
    "    seed = 0\n",
    "    key = random.PRNGKey(seed)\n",
    "    seeds = random.randint(key, (samples,), 0, jnp.uint32(2**32 - 1), dtype=jnp.uint32)\n",
    "    metrics_list = []\n",
    "\n",
    "    # load data once if not provided\n",
    "    if data_loaders is None:\n",
    "        data_loaders = load_data(datasets, config)\n",
    "\n",
    "    for seed in seeds:\n",
    "        config_theta = {**config, \"seed\": seed}\n",
    "        metrics, perf_metrics = run_theta(config_theta, data_loaders)\n",
    "        metrics_list.append(metrics | perf_metrics)\n",
    "    metrics = jax.tree.map(lambda *args: jnp.stack(args), *metrics_list)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_ensemble_metrics(ensemble_metrics: dict, epoch: int = -1) -> dict:\n",
    "    metrics = {}\n",
    "\n",
    "    for key, value in ensemble_metrics.items():\n",
    "        if key.startswith(\"perf.\"):\n",
    "            # Not epoch-specific\n",
    "            metrics[f\"{key}_mean\"] = float(jnp.mean(value))\n",
    "            metrics[f\"{key}_std\"] = float(jnp.std(value))\n",
    "        elif key not in [\"p_init\", \"p_end\"]:\n",
    "            # Epoch-specific\n",
    "            metrics[f\"{key}_mean\"] = float(jnp.mean(value[:, epoch]))\n",
    "            metrics[f\"{key}_std\"] = float(jnp.std(value[:, epoch]))\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_grid = {\n",
    "    \"seed\": 0,\n",
    "    # Neuron\n",
    "    \"tau\": 6 / np.pi,\n",
    "    \"I0\": 5 / 4,\n",
    "    \"eps\": 1e-6,\n",
    "    # Network\n",
    "    # \"Nin\": 7000, # must be N * Nt, where N is the number of neurons in the SHD dataset (700)\n",
    "    \"Nin_virtual\": (12, 16, 20),  # #Virtual input neurons = N_bin - 1\n",
    "    \"Nhidden\": (40, 60, 80, 100),\n",
    "    \"Nlayer\": (2, 3),  # Number of layers\n",
    "    \"Nout\": 20,\n",
    "    \"w_scale\": 0.5,  # Scaling factor of initial weights\n",
    "    # Trial\n",
    "    \"T\": 2.0,\n",
    "    \"K\": (50, 100, 150, 200),  # Maximal number of simulated ordinary spikes\n",
    "    \"dt\": 0.001,  # Step size used to compute state traces\n",
    "    # Training\n",
    "    \"gamma\": 1e-2,\n",
    "    \"Nbatch\": 1000,\n",
    "    \"lr\": 4e-3,\n",
    "    \"tau_lr\": 1e2,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"p_flip\": (0.0, 0.02, 0.04),\n",
    "    \"Nepochs\": 10,\n",
    "    \"Ntrain\": None,  # Number of training samples\n",
    "    # SHD Quantization\n",
    "    \"Nt\": (8, 12, 16),\n",
    "    \"Nin_data\": 700,\n",
    "}\n",
    "\n",
    "\n",
    "def configs_from_grid(config_grid: dict):\n",
    "    config_grid = {\n",
    "        k: v if isinstance(v, tuple) else (v,) for k, v in config_grid.items()\n",
    "    }\n",
    "\n",
    "    configs = [\n",
    "        dict(zip(config_grid.keys(), values))\n",
    "        for values in itertools.product(*config_grid.values())\n",
    "    ]\n",
    "\n",
    "    for config in configs:\n",
    "        config[\"Nin\"] = config[\"Nin_data\"] * config[\"Nt\"]\n",
    "\n",
    "    return configs\n",
    "\n",
    "\n",
    "def format_timestamp(t: float):\n",
    "    return datetime.fromtimestamp(t).strftime(\"%Y-%m-%d_%H-%M-%S_%f\")\n",
    "\n",
    "\n",
    "def parse_timestamp(t: str):\n",
    "    return datetime.strptime(t, \"%Y-%m-%d_%H-%M-%S_%f\").timestamp()\n",
    "\n",
    "\n",
    "def get_grid_data_filename(version: int):\n",
    "    return f\"grid_data_{version:02d}.yaml\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridData:\n",
    "    version: int\n",
    "    created_at: str\n",
    "    const: dict[str, Any] | None = None\n",
    "    trials: dict[int, \"GridTrial\"] = field(default_factory=dict)\n",
    "\n",
    "    def to_dict(self):\n",
    "        dict_ = asdict(self)\n",
    "        dict_[\"trials\"] = dict(trial.to_item() for trial in self.trials.values())\n",
    "        return dict_\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, dict_: dict):\n",
    "        dict_[\"trials\"] = {\n",
    "            k: GridTrial.from_item((k, v)) for k, v in dict_[\"trials\"].items()\n",
    "        }\n",
    "        return cls(**dict_)\n",
    "\n",
    "    def save(self):\n",
    "        filename = get_grid_data_filename(self.version)\n",
    "        with open(filename, \"w\") as f:\n",
    "            yaml.dump(self.to_dict(), f, sort_keys=False)\n",
    "\n",
    "    @classmethod\n",
    "    def load_or_create(cls, version: int) -> Self:\n",
    "        path = Path(get_grid_data_filename(version))\n",
    "\n",
    "        if not path.exists():\n",
    "            data = cls(version=version, created_at=format_timestamp(time.time()))\n",
    "            data.save()\n",
    "            return data\n",
    "        \n",
    "        # File exists -> create backup and load data\n",
    "        shutil.copy(path, path.with_stem(f\"{path.stem}_{time.strftime(\"%Y%m%d-%H%M%S\")}\"))\n",
    "\n",
    "        with path.open(\"r\") as f:\n",
    "            dict_ = yaml.safe_load(f)\n",
    "\n",
    "        data = cls.from_dict(dict_)\n",
    "\n",
    "        assert data.version == version, f\"Version mismatch: {data.version} != {version}\"\n",
    "\n",
    "        return data\n",
    "\n",
    "    def create_trial_config(self, config: dict[str, Any]) -> dict[str, Any]:\n",
    "        if self.const is None:\n",
    "            self.const = config.copy()\n",
    "            return {}\n",
    "\n",
    "        trial_config = {}\n",
    "\n",
    "        for key, const_value in list(self.const.items()):\n",
    "            new_value = config.get(key)\n",
    "\n",
    "            if const_value != new_value:\n",
    "                # Previously constant key is different now -> remove from const\n",
    "                self.const.pop(key, None)\n",
    "\n",
    "                # Add key with constant value to all existing trial configs\n",
    "                for trial in self.trials.values():\n",
    "                    assert (\n",
    "                        key not in trial.config\n",
    "                    ), f\"Key {key} already in trial config of trial {trial.index}.\"\n",
    "                    trial.config[key] = const_value\n",
    "\n",
    "        for key, new_value in config.items():\n",
    "            const_value = self.const.get(key)\n",
    "\n",
    "            if new_value != const_value:\n",
    "                # Add key with new value to trial config\n",
    "                trial_config[key] = new_value\n",
    "\n",
    "        return trial_config\n",
    "\n",
    "    def get_next_trial_index(self):\n",
    "        return max((trial.index for trial in self.trials.values()), default=0) + 1\n",
    "\n",
    "    def start_trial(self, config: dict[str, Any], n_samples: int) -> \"GridTrial\":\n",
    "        trial_config = self.create_trial_config(config)\n",
    "\n",
    "        trial = GridTrial(\n",
    "            index=self.get_next_trial_index(),\n",
    "            config=trial_config,\n",
    "            n_samples=n_samples,\n",
    "            started_at=format_timestamp(time.time()),\n",
    "        )\n",
    "        self.trials[trial.index] = trial\n",
    "        return trial\n",
    "\n",
    "    def find_trial_by_config(self, config: dict[str, Any]):\n",
    "        for trial in self.trials.values():\n",
    "            for k, v in config.items():\n",
    "                trial_value = trial.config.get(k)\n",
    "                if trial_value is None and self.const is not None:\n",
    "                    trial_value = self.const.get(k)\n",
    "\n",
    "                if v != trial_value:\n",
    "                    break\n",
    "            else:\n",
    "                return trial\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GridTrial:\n",
    "    index: int\n",
    "    config: dict[str, Any]\n",
    "    n_samples: int\n",
    "    started_at: str\n",
    "    finished_at: str | None = None\n",
    "    duration: float | None = None\n",
    "    metrics: dict[str, Any] = field(default_factory=dict)\n",
    "    error: str | None = None\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.index > 999:\n",
    "            raise ValueError(\"Trial indices above 999 are not supported.\")\n",
    "\n",
    "    def to_item(self):\n",
    "        return self.index, asdict(self)\n",
    "\n",
    "    @classmethod\n",
    "    def from_item(cls, item: tuple[int, dict[str, Any]]):\n",
    "        index, dict_ = item\n",
    "        assert isinstance(index, int), f\"Invalid trial index: {index}\"\n",
    "        assert isinstance(dict_, dict), f\"Invalid trial data: {dict_}\"\n",
    "\n",
    "        trial = cls(**dict_)\n",
    "        assert trial.index == index, f\"Trial index mismatch: {trial.index} != {index}\"\n",
    "        return trial\n",
    "\n",
    "    def finish(self, metrics: dict[str, Any], error: str | None = None):\n",
    "        self.metrics = metrics\n",
    "        self.error = error\n",
    "        end_time = time.time()\n",
    "        self.finished_at = format_timestamp(end_time)\n",
    "        self.duration = end_time - parse_timestamp(self.started_at)\n",
    "\n",
    "\n",
    "def print_dict(d: dict, value_format=\"\"):\n",
    "    for k, v in d.items():\n",
    "        print(f\"{k:<25} {v:{value_format}}\")\n",
    "\n",
    "\n",
    "def filter_dict[K, V](\n",
    "    d: dict[K, V], predicate: Callable[[K, V], bool] | Iterable[K]\n",
    ") -> dict[K, V]:\n",
    "    if isinstance(predicate, Iterable):\n",
    "        keys = predicate\n",
    "        predicate = lambda k, v: k in keys\n",
    "\n",
    "    return {k: v for k, v in d.items() if predicate(k, v)}\n",
    "\n",
    "\n",
    "def run_theta_grid(config_grid: dict, version: int, n_samples_per_trial=1):\n",
    "    configs = configs_from_grid(config_grid)\n",
    "    const_keys = [k for k, v in config_grid.items() if not isinstance(v, tuple)]\n",
    "    varying_keys = [k for k, v in config_grid.items() if isinstance(v, tuple)]\n",
    "\n",
    "\n",
    "    data = GridData.load_or_create(version)    \n",
    "    print_dict(\n",
    "        {\n",
    "            \"variables\": \", \".join(varying_keys),\n",
    "            \"samples per trial\": n_samples_per_trial,\n",
    "            \"configs\": len(configs),\n",
    "        }\n",
    "    )\n",
    "    print(\"========== CONSTANTS ==========\")\n",
    "    print_dict(filter_dict(config_grid, const_keys))\n",
    "    print()\n",
    "\n",
    "    print()\n",
    "\n",
    "    for config in configs:\n",
    "        trial_index = data.get_next_trial_index()\n",
    "        print(f\"========== TRIAL {trial_index:03d} ==========\")\n",
    "        print_dict(filter_dict(config, varying_keys))\n",
    "\n",
    "        # Check if this config has already been run\n",
    "        trial = data.find_trial_by_config(config)\n",
    "\n",
    "        if trial is not None:\n",
    "            print(f\"This config has already been used in trial {trial.index}.\")\n",
    "            print()\n",
    "            continue\n",
    "\n",
    "        trial = data.start_trial(config, n_samples_per_trial)\n",
    "\n",
    "        try:\n",
    "            ensemble_metrics = run_theta_ensemble(config, samples=n_samples_per_trial)\n",
    "        except Exception as e:\n",
    "            trial.finish({}, repr(e))\n",
    "            print_dict({\"error\": repr(e)})\n",
    "        else:\n",
    "            metrics = summarize_ensemble_metrics(ensemble_metrics)\n",
    "            trial.finish(metrics)\n",
    "            print_dict(filter_dict(metrics, (\"acc_mean\", \"acc_std\")), \".3f\")\n",
    "\n",
    "        print()\n",
    "\n",
    "        data.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables                 Nin_virtual, Nhidden, Nlayer, K, Nbatch, lr, p_flip, Nt\n",
      "samples per trial         3\n",
      "configs                   13824\n",
      "========== CONSTANTS ==========\n",
      "seed                      0\n",
      "tau                       1.909859317102744\n",
      "I0                        1.25\n",
      "eps                       1e-06\n",
      "Nout                      20\n",
      "w_scale                   0.5\n",
      "T                         2.0\n",
      "dt                        0.001\n",
      "gamma                     0.01\n",
      "tau_lr                    100.0\n",
      "beta1                     0.9\n",
      "beta2                     0.999\n",
      "Nepochs                   10\n",
      "Ntrain                    None\n",
      "Nin_data                  700\n",
      "\n",
      "\n",
      "========== TRIAL 001 ==========\n",
      "Nin_virtual               12\n",
      "Nhidden                   40\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "Nbatch                    100\n",
      "lr                        0.001\n",
      "p_flip                    0.0\n",
      "Nt                        8\n"
     ]
    }
   ],
   "source": [
    "run_theta_grid(config_grid, version=1, n_samples_per_trial=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikegd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
