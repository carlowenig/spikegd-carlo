{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import shutil\n",
    "import time\n",
    "from dataclasses import asdict, dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Iterable, Literal, Self\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from jax import random\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "from heidelberg_v01 import (\n",
    "    load_data,\n",
    "    load_datasets,\n",
    "    plot_error,\n",
    "    plot_spikes,\n",
    "    plot_traces,\n",
    "    run,\n",
    "    run_example,\n",
    ")\n",
    "from hyperparam_scan_util import computed, scan_grid, vary\n",
    "from spikegd.theta import ThetaNeuron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from h5 file\n",
      "Loading audio filenames\n",
      "Finished loading SHD\n",
      "Loading data from h5 file\n",
      "Loading audio filenames\n",
      "Finished loading SHD\n"
     ]
    }
   ],
   "source": [
    "datasets = load_datasets(\"data\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_theta(config: dict, data_loaders=None):\n",
    "    \"\"\"\n",
    "    Wrapper to train a network of Theta neurons with the given configuration.\n",
    "\n",
    "    See docstring of `run` and article for more information.\n",
    "    \"\"\"\n",
    "    if data_loaders is None:\n",
    "        data_loaders = load_data(datasets, config)\n",
    "\n",
    "    tau, I0, eps = config[\"tau\"], config[\"I0\"], config[\"eps\"]\n",
    "    neuron = ThetaNeuron(tau, I0, eps)\n",
    "    metrics, perf_metrics = run(neuron, data_loaders, config, progress_bar=\"script\")\n",
    "    return metrics, perf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_ensemble_metrics(ensemble_metrics: dict, Nepochs: int) -> dict:\n",
    "    metrics: dict = {}\n",
    "    # epoch 0 is the initial state, other epochs are counted from 1\n",
    "    epoch_metrics = [{} for _ in range(Nepochs + 1)]\n",
    "\n",
    "    for key, value in ensemble_metrics.items():\n",
    "        if key in [\"p_init\", \"p_end\"]:\n",
    "            continue\n",
    "\n",
    "        is_global = key.startswith(\"perf.\")\n",
    "\n",
    "        if is_global:\n",
    "            metrics[f\"{key}_mean\"] = float(jnp.mean(value))\n",
    "            metrics[f\"{key}_std\"] = float(jnp.std(value))\n",
    "        else:\n",
    "            min_mean = None\n",
    "            min_mean_epoch = None\n",
    "            max_mean = None\n",
    "            max_mean_epoch = None\n",
    "\n",
    "            if value.shape[1] != Nepochs + 1:\n",
    "                raise ValueError(f\"Expected {Nepochs + 1} (Nepochs + 1) values, got {value.shape[1]} in {key}\")\n",
    "            \n",
    "            for epoch in range(Nepochs + 1):\n",
    "                mean = float(jnp.mean(value[:, epoch]))\n",
    "                std = float(jnp.std(value[:, epoch]))\n",
    "\n",
    "                epoch_dict = epoch_metrics[epoch]\n",
    "                epoch_dict[f\"{key}_mean\"] = mean\n",
    "                epoch_dict[f\"{key}_std\"] = std\n",
    "\n",
    "                if min_mean is None or mean < min_mean:\n",
    "                    min_mean = mean\n",
    "                    min_mean_epoch = epoch\n",
    "                if max_mean is None or mean > max_mean:\n",
    "                    max_mean = mean\n",
    "                    max_mean_epoch = epoch\n",
    "\n",
    "            # Also store init, final, min and max values for convenience\n",
    "            metrics[f\"{key}_init_mean\"] = epoch_metrics[0][f\"{key}_mean\"]\n",
    "            metrics[f\"{key}_init_std\"] = epoch_metrics[0][f\"{key}_std\"]\n",
    "\n",
    "            metrics[f\"{key}_final_mean\"] = epoch_metrics[Nepochs][f\"{key}_mean\"]\n",
    "            metrics[f\"{key}_final_std\"] = epoch_metrics[Nepochs][f\"{key}_std\"]\n",
    "\n",
    "            if min_mean_epoch is not None:\n",
    "                metrics[f\"{key}_min_epoch\"] = min_mean_epoch\n",
    "                metrics[f\"{key}_min_mean\"] = min_mean\n",
    "                metrics[f\"{key}_min_std\"] = epoch_metrics[min_mean_epoch][f\"{key}_std\"]\n",
    "\n",
    "            if max_mean_epoch is not None:\n",
    "                metrics[f\"{key}_max_epoch\"] = max_mean_epoch                    \n",
    "                metrics[f\"{key}_max_mean\"] = max_mean\n",
    "                metrics[f\"{key}_max_std\"] = epoch_metrics[max_mean_epoch][f\"{key}_std\"]\n",
    "\n",
    "    metrics[\"epochs\"] = epoch_metrics\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def run_theta_ensemble(config: dict, data_loaders=None) -> dict:\n",
    "    seed = config.get(\"seed\", 0)\n",
    "    Nsamples = config.get(\"Nsamples\", 1)\n",
    "    Nepochs = config[\"Nepochs\"]\n",
    "\n",
    "    key = random.PRNGKey(seed)\n",
    "    seeds = random.randint(key, (Nsamples,), 0, jnp.uint32(2**32 - 1), dtype=jnp.uint32)\n",
    "    metrics_list = []\n",
    "\n",
    "    # load data once if not provided\n",
    "    if data_loaders is None:\n",
    "        data_loaders = load_data(datasets, config)\n",
    "\n",
    "    for seed in seeds:\n",
    "        config_theta = {**config, \"seed\": seed}\n",
    "        metrics, perf_metrics = run_theta(config_theta, data_loaders)\n",
    "        metrics_list.append(metrics | perf_metrics)\n",
    "    metrics = jax.tree.map(lambda *args: jnp.stack(args), *metrics_list)\n",
    "    \n",
    "    return summarize_ensemble_metrics(metrics, Nepochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_grid = {\n",
    "    \"seed\": 0,\n",
    "    # Neuron\n",
    "    \"tau\": 6 / np.pi,\n",
    "    \"I0\": 5 / 4,\n",
    "    \"eps\": 1e-6,\n",
    "    # Network\n",
    "    # \"Nin\": 7000, # must be N * Nt, where N is the number of neurons in the SHD dataset (700)\n",
    "    \"Nin_virtual\": vary(12, 16, 20),  # #Virtual input neurons = N_bin - 1\n",
    "    \"Nhidden\": vary(40, 60, 80, 100),\n",
    "    \"Nlayer\": vary(2, 3),  # Number of layers\n",
    "    \"Nout\": 20,\n",
    "    \"w_scale\": 0.5,  # Scaling factor of initial weights\n",
    "    # Trial\n",
    "    \"T\": 2.0,\n",
    "    \"K\": vary(50, 100, 150, 200),  # Maximal number of simulated ordinary spikes\n",
    "    \"dt\": 0.001,  # Step size used to compute state traces\n",
    "    # Training\n",
    "    \"gamma\": 1e-2,\n",
    "    \"Nbatch\": 1000,\n",
    "    \"lr\": 4e-3,\n",
    "    \"tau_lr\": 1e2,\n",
    "    \"beta1\": 0.9,\n",
    "    \"beta2\": 0.999,\n",
    "    \"p_flip\": vary(0.0, 0.02, 0.04),\n",
    "    \"Nepochs\": 10,\n",
    "    \"Ntrain\": None,  # Number of training samples\n",
    "    # SHD Quantization\n",
    "    \"Nt\": vary(8, 12, 16),\n",
    "    \"Nin_data\": 700,\n",
    "    \"Nin\": computed(lambda Nin_data, Nt: Nin_data * Nt),\n",
    "    # Ensemble\n",
    "    \"Nsamples\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varying keys              Nin_virtual, Nhidden, Nlayer, K, p_flip, Nt, Nin\n",
      "configs                   864\n",
      "========== CONSTANTS ==========\n",
      "seed                      0\n",
      "tau                       1/6 pi^-1\n",
      "I0                        1.25\n",
      "eps                       1e-06\n",
      "Nout                      20\n",
      "w_scale                   0.5\n",
      "T                         2.0\n",
      "dt                        0.001\n",
      "gamma                     0.01\n",
      "Nbatch                    1000\n",
      "lr                        0.004\n",
      "tau_lr                    100.0\n",
      "beta1                     0.9\n",
      "beta2                     0.999\n",
      "Nepochs                   10\n",
      "Ntrain                    None\n",
      "Nin_data                  700\n",
      "Nsamples                  3\n",
      "\n",
      "\n",
      "========== CONFIG 001 ==========\n",
      "Nin_virtual               12\n",
      "Nhidden                   40\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 1 and had no error. Skipping.\n",
      "========== CONFIG 002 ==========\n",
      "Nin_virtual               16\n",
      "Nhidden                   40\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 2 and had no error. Skipping.\n",
      "========== CONFIG 003 ==========\n",
      "Nin_virtual               20\n",
      "Nhidden                   40\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 3 and had no error. Skipping.\n",
      "========== CONFIG 004 ==========\n",
      "Nin_virtual               12\n",
      "Nhidden                   60\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 4 and had no error. Skipping.\n",
      "========== CONFIG 005 ==========\n",
      "Nin_virtual               12\n",
      "Nhidden                   80\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 5 and had no error. Skipping.\n",
      "========== CONFIG 006 ==========\n",
      "Nin_virtual               12\n",
      "Nhidden                   100\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 6 and had no error. Skipping.\n",
      "========== CONFIG 007 ==========\n",
      "Nin_virtual               16\n",
      "Nhidden                   60\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 7 and had no error. Skipping.\n",
      "========== CONFIG 008 ==========\n",
      "Nin_virtual               16\n",
      "Nhidden                   80\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 8 and had no error. Skipping.\n",
      "========== CONFIG 009 ==========\n",
      "Nin_virtual               16\n",
      "Nhidden                   100\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 9 and had no error. Skipping.\n",
      "========== CONFIG 010 ==========\n",
      "Nin_virtual               20\n",
      "Nhidden                   60\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 10 and had no error. Skipping.\n",
      "========== CONFIG 011 ==========\n",
      "Nin_virtual               20\n",
      "Nhidden                   80\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 11 and had no error. Skipping.\n",
      "========== CONFIG 012 ==========\n",
      "Nin_virtual               20\n",
      "Nhidden                   100\n",
      "Nlayer                    2\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "This config has already been used in trial 12 but had an error. Recomputing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:12<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: A NaN appeared. Likely not enough spikes have been simulated. Try increasing `K`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_max_epoch             10\n",
      "acc_max_mean              0.17445455491542816\n",
      "acc_max_std               0.11381981521844864\n",
      "\n",
      "Remaining: 852 configs (34304.5s, ETA: 03:13:22)\n",
      "\n",
      "========== CONFIG 013 ==========\n",
      "Nin_virtual               12\n",
      "Nhidden                   40\n",
      "Nlayer                    3\n",
      "K                         50\n",
      "p_flip                    0.0\n",
      "Nt                        8\n",
      "Nin                       5600\n",
      "Starting trial 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: A NaN appeared. Likely not enough spikes have been simulated. Try increasing `K`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:08<00:00,  1.20it/s]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "scan_grid(run_theta_ensemble, config_grid, version=1,\n",
    "          show_metrics=(\"acc_max_epoch\", \"acc_max_mean\", \"acc_max_std\"),\n",
    "          if_trial_exists=\"recompute_if_error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spikegd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
